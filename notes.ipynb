{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 82  82  82]\n",
      "  [ 67  67  67]\n",
      "  [ 45  45  45]\n",
      "  ...\n",
      "  [ 68  68  68]\n",
      "  [ 11  11  11]\n",
      "  [  2   2   2]]\n",
      "\n",
      " [[ 45  45  45]\n",
      "  [ 16  16  16]\n",
      "  [ 64  64  64]\n",
      "  ...\n",
      "  [ 62  62  62]\n",
      "  [ 72  72  72]\n",
      "  [ 26  26  26]]\n",
      "\n",
      " [[ 58  58  58]\n",
      "  [ 39  39  39]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [ 83  83  83]\n",
      "  [ 55  55  55]\n",
      "  [ 65  65  65]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[137 137 137]\n",
      "  [ 82  82  82]\n",
      "  [125 125 125]\n",
      "  ...\n",
      "  [171 171 171]\n",
      "  [153 153 153]\n",
      "  [153 153 153]]\n",
      "\n",
      " [[139 139 139]\n",
      "  [117 117 117]\n",
      "  [133 133 133]\n",
      "  ...\n",
      "  [101 101 101]\n",
      "  [ 87  87  87]\n",
      "  [ 63  63  63]]\n",
      "\n",
      " [[135 135 135]\n",
      "  [145 145 145]\n",
      "  [132 132 132]\n",
      "  ...\n",
      "  [100 100 100]\n",
      "  [120 120 120]\n",
      "  [ 82  82  82]]]\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.imread('/zhome/ac/d/174101/thesis/test.jpeg')\n",
    "print(image_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeMeanStdNormalize:\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 0.\n",
    "        self.num_samples = 0\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Incrementally update mean and std\n",
    "        img = torch.tensor(img, dtype=torch.float32) / 255.  # Convert image to tensor and normalize\n",
    "        self.mean += torch.mean(img, dim=(0, 1))\n",
    "        self.std += torch.std(img, dim=(0, 1))\n",
    "        self.num_samples += 1\n",
    "        return img\n",
    "\n",
    "    def get_mean_std(self):\n",
    "        # Calculate mean and std across all batches\n",
    "        return self.mean / self.num_samples, self.std / self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image([[[0.3216, 0.2627, 0.1765,  ..., 0.2667, 0.0431, 0.0078],\n",
      "        [0.1765, 0.0627, 0.2510,  ..., 0.2431, 0.2824, 0.1020],\n",
      "        [0.2275, 0.1529, 0.1098,  ..., 0.3255, 0.2157, 0.2549],\n",
      "        ...,\n",
      "        [0.5373, 0.3216, 0.4902,  ..., 0.6706, 0.6000, 0.6000],\n",
      "        [0.5451, 0.4588, 0.5216,  ..., 0.3961, 0.3412, 0.2471],\n",
      "        [0.5294, 0.5686, 0.5176,  ..., 0.3922, 0.4706, 0.3216]],\n",
      "\n",
      "       [[0.3216, 0.2627, 0.1765,  ..., 0.2667, 0.0431, 0.0078],\n",
      "        [0.1765, 0.0627, 0.2510,  ..., 0.2431, 0.2824, 0.1020],\n",
      "        [0.2275, 0.1529, 0.1098,  ..., 0.3255, 0.2157, 0.2549],\n",
      "        ...,\n",
      "        [0.5373, 0.3216, 0.4902,  ..., 0.6706, 0.6000, 0.6000],\n",
      "        [0.5451, 0.4588, 0.5216,  ..., 0.3961, 0.3412, 0.2471],\n",
      "        [0.5294, 0.5686, 0.5176,  ..., 0.3922, 0.4706, 0.3216]],\n",
      "\n",
      "       [[0.3216, 0.2627, 0.1765,  ..., 0.2667, 0.0431, 0.0078],\n",
      "        [0.1765, 0.0627, 0.2510,  ..., 0.2431, 0.2824, 0.1020],\n",
      "        [0.2275, 0.1529, 0.1098,  ..., 0.3255, 0.2157, 0.2549],\n",
      "        ...,\n",
      "        [0.5373, 0.3216, 0.4902,  ..., 0.6706, 0.6000, 0.6000],\n",
      "        [0.5451, 0.4588, 0.5216,  ..., 0.3961, 0.3412, 0.2471],\n",
      "        [0.5294, 0.5686, 0.5176,  ..., 0.3922, 0.4706, 0.3216]]], )\n"
     ]
    }
   ],
   "source": [
    "transform = v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])\n",
    "img_tr = transform(image_gray)\n",
    "print(img_tr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39marray(img_tr\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\n",
      "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (int, int, int), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.imshow(np.array(img_tr.transpose(1, 2, 0)))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and std before normalize:\n",
      "Mean of the image: tensor([0.6762, 0.6762, 0.6762])\n",
      "Std of the image: tensor([0.2395, 0.2395, 0.2395])\n"
     ]
    }
   ],
   "source": [
    "mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
    "print(\"mean and std before normalize:\")\n",
    "print(\"Mean of the image:\", mean)\n",
    "print(\"Std of the image:\", std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fungi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
